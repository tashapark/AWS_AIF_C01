{
  "A CSV file with tabular data": "테이블 형식 데이터가 포함된 CSV 파일",
  "A CSV file with unlabeled data": "라벨 없는 데이터가 포함된 CSV 파일",
  "A JSON file with labeled data": "라벨이 있는 데이터가 포함된 JSON 파일",
  "A diffusion model": "확산 모델",
  "A generative adversarial network (GAN) model": "생성적 적대 신경망(GAN) 모델",
  "A method for compressing large datasets": "대용량 데이터셋 압축 방법",
  "A method for visualizing high-dimensional data": "고차원 데이터 시각화 방법",
  "A model that classifies images as dogs or cats": "이미지를 개 또는 고양이로 분류하는 모델",
  "A model that groups customers based on their purchase history": "구매 이력을 기반으로 고객을 그룹화하는 모델",
  "A model that learns to play chess by using trial and error": "시행착오를 통해 체스를 배우는 모델",
  "A model that predicts a house㐴s price based on various features": "다양한 특성을 기반으로 집 가격을 예측하는 모델",
  "A numerical method for data representation in a reduced dimensionality space": "축소된 차원 공간에서 데이터 표현을 위한 수치 방법",
  "A text file with unlabeled data": "라벨 없는 데이터가 포함된 텍스트 파일",
  "A transformer-based model": "트랜스포머 기반 모델",
  "A variational autoencoder (VAE) model": "변분 자동 인코더(VAE) 모델",
  "AWS AI Service Cards": "AWS AI 서비스 카드",
  "AWS Artifact": "AWS Artifact",
  "AWS Audit Manager": "AWS Audit Manager",
  "AWS Cloud Formation": "AWS CloudFormation",
  "AWS CloudTrail": "모델의 응답을 모니터링하고 감지된 개인정보에 대한 알림을 생성하기 위해 AWS CloudTrail 구성",
  "AWS Config": "AWS Config",
  "AWS Data Exchange": "AWS Data Exchange",
  "AWS DeepRacer": "AWS DeepRacer",
  "AWS HealthScribe": "AWS HealthScribe",
  "AWS Key Management Service (AWS KMS)": "AWS Key Management Service (AWS KMS)",
  "AWS PrivateLink": "AWS PrivateLink",
  "AWS Secrets Manager": "AWS Secrets Manager",
  "AWS Snowcone": "AWS Snowcone",
  "AWS Trusted Advisor": "AWS Trusted Advisor",
  "Ability to generate creative content": "창의적인 콘텐츠 생성 능력",
  "Ability to perform real-time analysis on streaming data": "스트리밍 데이터에 대한 실시간 분석 수행 능력",
  "Accuracy": "정확도",
  "Active learning 44": "능동 학습",
  "Adaptability": "적응성",
  "Add Amazon Personalize to the company㐴s website.": "회사 웹사이트에 Amazon Personalize 추가",
  "Add Amazon Transcribe to the company㐴s website.": "회사 웹사이트에 Amazon Transcribe 추가",
  "Add a role description to the prompt context that instructs the model of the age range that the response should target. 26": "응답이 타겟팅해야 할 연령대를 모델에 지시하는 역할 설명을 프롬프트 컨텍스트에 추가",
  "Add hyperparameters to the model.": "모델에 하이퍼파라미터 추가",
  "Add messages to the model prompt.": "모델 프롬프트에 메시지 추가",
  "Add more features to the input data.": "입력 데이터에 더 많은 특성 추가",
  "Adjust the monitoring sensitivity.": "모니터링 민감도 조정.",
  "Adjust the prompt.": "프롬프트 조정.",
  "Adjust the temperature parameter of the model.": "모델의 온도 파라미터 조정",
  "Adversarial training": "Adversarial 학습",
  "Agents": "에이전트",
  "Agents for Amazon Bedrock": "Amazon Bedrock용 에이전트",
  "All AI application team members are ISO certified.": "모든 AI 애플리케이션 팀 멤버가 ISO 인증을 받았습니다",
  "All AI systems that the company uses are ISO certified.": "회사가 사용하는 모든 AI 시스템이 ISO 인증을 받았습니다",
  "All members of the company are ISO certified.": "회사의 모든 멤버가 ISO 인증을 받았습니다",
  "Amazon Athena": "Amazon Athena (서버리스 쿼리 서비스)",
  "Amazon Augmented AI (Amazon A2I) 4": "Amazon Augmented AI (Amazon A2I)",
  "Amazon Aurora PostgreSQL": "Amazon Aurora PostgreSQL",
  "Amazon Bedrock": "중간 이미지를 생성하기 위해 Amazon Bedrock의 Amazon Nova Canvas 모델 사용. 비디오를 생성하기 위해 비디오 편집 소프트웨어 사용",
  "Amazon Bedrock Agents": "Amazon Bedrock Agents",
  "Amazon Bedrock Guardrails": "Amazon Bedrock Guardrails",
  "Amazon Bedrock PartyRock": "Amazon Bedrock PartyRock",
  "Amazon Bedrock custom models": "Amazon Bedrock 사용자 정의 모델",
  "Amazon Bedrock inference APIs": "Amazon Bedrock 추론 APIs",
  "Amazon Bedrock playground": "Amazon Bedrock Playground",
  "Amazon Bedrock playgrounds": "Amazon Bedrock Playground",
  "Amazon CloudFront": "회사의 프라이빗 콘텐츠에 대한 액세스를 제한하기 위해 Amazon CloudFront 사용",
  "Amazon CloudWatch": "Amazon CloudWatch (모니터링 서비스)",
  "Amazon Comprehend": "Amazon Comprehend (자연어 처리 서비스)",
  "Amazon Comprehend 5": "Amazon Comprehend (자연어 처리 서비스)",
  "Amazon DynamoDB": "Amazon DynamoDB (NoSQL 데이터베이스 서비스)",
  "Amazon EC2 C series": "Amazon EC2 C 시리즈",
  "Amazon EC2 G series": "Amazon EC2 G 시리즈",
  "Amazon EC2 P series 20": "Amazon EC2 P 시리즈",
  "Amazon EC2 Trn series": "Amazon EC2 Trn 시리즈",
  "Amazon EMR": "Amazon EMR (빅데이터 처리 서비스)",
  "Amazon ElastiCache": "Amazon ElastiCache (인메모리 캐시 서비스)",
  "Amazon Elastic Block Store (Amazon EBS)": "Amazon Elastic Block Store (Amazon EBS)",
  "Amazon Elastic File System (Amazon EFS)": "Amazon Elastic File System (Amazon EFS)",
  "Amazon Fraud Detector": "Amazon Fraud Detector (사기 탐지 서비스)",
  "Amazon Inspector": "Amazon Inspector",
  "Amazon Kendra": "Amazon Kendra (엔터프라이즈 검색 서비스)",
  "Amazon Lex": "Amazon Lex (대화형 챗봇 서비스)",
  "Amazon Macie": "Amazon Macie",
  "Amazon OpenSearch Service": "Amazon OpenSearch Service (검색 및 분석 서비스)",
  "Amazon Personalize": "Amazon Personalize (개인화 추천 서비스)",
  "Amazon Personalize 37": "Amazon Personalize (개인화 추천 서비스)",
  "Amazon Polly": "Amazon Polly (음성 합성 서비스)",
  "Amazon Polly 17": "Amazon Polly (음성 합성 서비스)",
  "Amazon Q": "Amazon Q",
  "Amazon Q Business": "Amazon Q Business",
  "Amazon Q Business 6": "Amazon Q Business",
  "Amazon Q Developer": "Amazon Q Developer",
  "Amazon Q in AWS Chatbot": "AWS Chatbot의 Amazon Q",
  "Amazon Q in Amazon EC2": "Amazon EC2의 Amazon Q",
  "Amazon Q in Amazon QuickSight": "Amazon QuickSight의 Amazon Q",
  "Amazon QuickSight": "Amazon QuickSight (비즈니스 인텔리전스 서비스)",
  "Amazon Redshift": "Amazon Redshift (데이터 웨어하우스 서비스)",
  "Amazon Rekognition": "Amazon Rekognition (이미지 및 비디오 분석 서비스)",
  "Amazon S3": "Amazon S3 (객체 스토리지 서비스)",
  "Amazon S3 Intelligent-Tiering": "Amazon S3 Intelligent-Tiering",
  "Amazon S3 Standard": "Amazon S3 Standard",
  "Amazon SageMaker": "Amazon SageMaker (머신러닝 플랫폼)",
  "Amazon SageMaker Canvas": "Amazon SageMaker Canvas",
  "Amazon SageMaker Canvas 41": "Amazon SageMaker Canvas",
  "Amazon SageMaker Clarify": "Amazon SageMaker Clarify (모델 편향성 분석 서비스)",
  "Amazon SageMaker Data Wrangler": "Amazon SageMaker Data Wrangler",
  "Amazon SageMaker Debugger": "Amazon SageMaker Debugger",
  "Amazon SageMaker Feature Store": "Amazon SageMaker Feature Store (피처 스토어)",
  "Amazon SageMaker Ground Truth": "Amazon SageMaker Ground Truth (데이터 라벨링 서비스)",
  "Amazon SageMaker Ground Truth Plus": "Amazon SageMaker Ground Truth Plus (데이터 라벨링 서비스)",
  "Amazon SageMaker HyperPod": "Amazon SageMaker HyperPod",
  "Amazon SageMaker JumpStart": "Amazon SageMaker JumpStart",
  "Amazon SageMaker Jumpstart": "Amazon SageMaker JumpStart",
  "Amazon SageMaker Model Card": "Amazon SageMaker Model Card",
  "Amazon SageMaker Model Cards": "Amazon SageMaker Model Card",
  "Amazon SageMaker Model Monitor": "Amazon SageMaker Model Monitor (모델 모니터링 서비스)",
  "Amazon SageMaker Model Registry": "Amazon SageMaker Model Registry",
  "Amazon SageMaker endpoints": "Amazon SageMaker 엔드포인트",
  "Amazon Textract": "Amazon Textract (문서 텍스트 추출 서비스)",
  "Amazon Transcribe": "Amazon Transcribe (음성-텍스트 변환 서비스)",
  "Amazon Translate": "Amazon Translate (번역 서비스)",
  "Amount of data used to train the LLM": "LLM 학습에 사용된 데이터 양",
  "An encryption method for securing sensitive data": "민감한 데이터를 보호하기 위한 암호화 방법",
  "Analyze cost and usage reports in AWS Cost Explorer.": "AWS Cost Explorer에서 비용 및 사용 보고서 분석",
  "Analyze industry AI implementations and replicate the most successful features.": "업계 AI 구현 분석 및 가장 성공적인 기능 복제",
  "Analyze the model㑄s architecture and hyperparameters.": "모델의 아키텍처와 하이퍼파라미터 분석",
  "Analyzing financial data to forecast stock market trends": "주식 시장 동향 예측을 위한 금융 데이터 분석",
  "Anomaly detection": "이상 탐지",
  "Apply explainable AI techniques to show customers which factors influenced the model㐴s decision.": "설명 가능한 AI 기법을 적용하여 고객에게 어떤 요소가 결정에 영향을 미쳤는지 보여줌",
  "Apply prompt engineering techniques.": "프롬프트 엔지니어링 기법 적용",
  "Area Under the ROC Curve (AUC) score": "ROC 곡선 아래 영역 (AUC) 점수",
  "Area under the ROC curve (AUC)": "ROC 곡선 아래 영역 (AUC)",
  "Ask the customers to avoid sharing sensitive information in their email messages.": "고객에게 이메일 메시지에서 민감한 정보 공유를 피하도록 요청",
  "Assess the color accuracy of images processed by the model.": "모델이 처리한 이미지의 색상 정확도 평가",
  "Assess the model㑄s alignment with specific use cases.": "특정 사용 사례와의 모델 정렬 평가",
  "Associate appropriate AWS Identity and Access Management (IAM) roles with the SageMaker jobs.": "SageMaker 작업에 적절한 AWS Identity and Access Management (IAM) 역할 연결",
  "Asynchronous inference": "비동기 추론",
  "Audio data": "오디오 데이터",
  "Auto scaling inference endpoints": "자동 확장 추론 엔드포인트",
  "Autoencoders": "자동 인코더",
  "Automate user feedback integration.": "사용자 피드백 통합 자동화",
  "Automatic model evaluation": "자동 모델 평가",
  "Automatically calling multiple foundation models (FMs) and consolidating the results": "여러 파운데이션 모델(FM)을 자동으로 호출하고 결과 통합",
  "Automation of repetitive tasks and orchestration of complex workflows": "반복 작업 자동화 및 복잡한 워크플로우 오케스트레이션",
  "Autoregressive Integrated Moving Average (ARIMA)": "자기회귀 통합 이동 평균 (ARIMA)",
  "Average call duration 16": "평균 통화 시간",
  "Average handled time (AHT)": "평균 처리 시간 (AHT)",
  "Average response time": "평균 응답 시간",
  "Avoid overfitting on the training data.": "학습 데이터에 대한 과적합 피하기",
  "Avoid using LLMs that are not listed in Amazon SageMaker.": "Amazon SageMaker에 나열되지 않은 LLM 사용 피하기.",
  "BERT-based models": "BERT 기반 모델",
  "BERTScore": "BERTScore",
  "Batch inference": "배치 추론",
  "Batch learning": "배치 학습",
  "Batch size": "배치 크기 감소",
  "Batch transform": "배치 변환",
  "Benchmark datasets": "벤치마크 데이터셋",
  "Bias correction": "편향 보정",
  "Bilingual Evaluation Understudy (BLEU)": "양국어 평가 보조 (BLEU)",
  "Bilingual Evaluation Understudy (BLEU) score": "양국어 평가 보조 (BLEU) 점수",
  "Binaries": "바이너리",
  "Binary classification": "이진 분류",
  "Binary data": "이진 데이터",
  "Block interactions related to predefined topics.": "미리 정의된 주제와 관련된 상호작용 차단",
  "Build ML models to search for patterns in numeric data.": "구축 ML models to search for patterns in numeric data.",
  "Build a conversational chatbot by using Amazon Lex.": "Amazon Lex를 사용하여 대화형 챗봇 구축",
  "Build a hybrid search solution by using Amazon OpenSearch Service.": "Amazon OpenSearch Service를 사용하여 하이브리드 검색 솔루션 구축",
  "Build a new model. Monitor model drift by using Amazon SageMaker Feature Store.": "새 모델 구축. Amazon SageMaker Feature Store를 사용하여 모델 드리프트 모니터링",
  "Build a new model. Monitor model drift by using Amazon SageMaker JumpStart.": "새 모델 구축. Amazon SageMaker JumpStart를 사용하여 모델 드리프트 모니터링",
  "Build a speech recognition system.": "음성 인식 시스템 구축",
  "Build an automatic named entity recognition system.": "자동 명명된 개체 인식 시스템 구축.",
  "Build custom models for image classification and recognition.": "구축 custom models for image classification and recognition.",
  "Building an application by using an existing third-party generative AI foundation model (FM).": "기존 서드파티 생성형 AI 기반 모델(FM)을 사용한 애플리케이션 구축",
  "Building and training a generative AI model from scratch by using specific data that a customer owns.": "고객이 소유한 특정 데이터를 사용하여 처음부터 생성형 AI 모델 구축 및 학습.",
  "Business goal identification": "비즈니스 목표 식별",
  "Calculate the total cost of resources used by the model.": "모델이 사용한 리소스의 총 비용 계산",
  "Chain-of-thought prompting": "Chain-of-thought 프롬프팅 (사고 과정 프롬프팅)",
  "Change the FM inference parameters. 24": "FM 추론 파라미터 변경",
  "Change the FM to a more secure FM.": "더 안전한 FM으로 FM 변경",
  "Choose a different FM on Amazon Bedrock.": "Amazon Bedrock에서 다른 FM 선택",
  "Choose a lower temperature value.": "더 낮은 온도 값 선택.",
  "Choose an LLM of a different size.": "다른 크기의 LLM 선택.",
  "Classification": "분류",
  "Classifying customers based on product usage": "제품 사용을 기반으로 고객 분류",
  "Clean the research paper data to remove complex scientific terms.": "연구 논문 데이터를 정리하여 복잡한 과학 용어 제거",
  "Clustering": "클러스터링",
  "Clustering data points into groups based on their similarity": "유사성을 기반으로 데이터 포인트를 그룹으로 클러스터링",
  "Clustering models": "유사성을 기반으로 데이터 포인트를 그룹으로 클러스터링",
  "Code for model training": "모델 학습용 코드",
  "Code generation speed and error handling capabilities": "코드 생성 속도 및 오류 처리 기능",
  "Collect data from customers who have a past purchase history.": "과거 구매 이력이 있는 고객으로부터 데이터 수집",
  "Collect external company reviews from various online sources. Manually label each review as either positive or negative.": "다양한 온라인 소스에서 외부 회사 리뷰 수집. 데이터를 수동으로 라벨링",
  "Complexity-based prompting": "복잡도 기반 프롬프팅",
  "Computer vision": "컴퓨터 비전",
  "Computer vision model": "컴퓨터 비전 모델",
  "Concept drift": "개념 드리프트",
  "Conduct stakeholder interviews to refine use cases and set measurable goals.": "사용 사례를 정제하고 측정 가능한 목표를 설정하기 위해 이해관계자 인터뷰 수행",
  "Configure AWS Audit Manager as the logs destination for the model.": "구성 AWS Audit Manager as the logs destination for the model.",
  "Configure AWS CloudTrail as the logs destination for the model.": "모델의 응답을 모니터링하고 감지된 개인정보에 대한 알림을 생성하기 위해 AWS CloudTrail 구성",
  "Configure AWS CloudTrail to monitor the model㑄s responses and create alerts for any detected personal information.": "모델의 응답을 모니터링하고 감지된 개인정보에 대한 알림을 생성하기 위해 AWS CloudTrail 구성",
  "Configure Amazon Bedrock Guardrails to evaluate user inputs and model responses.": "Amazon Bedrock Guardrails를 구성하여 사용자 입력 및 모델 응답 평가",
  "Configure Amazon Macie to detect sensitive information in the documents that are uploaded to Amazon S3. 9": "Amazon Macie를 구성하여 Amazon S3에 업로드된 문서에서 민감한 정보 감지",
  "Configure Amazon SageMaker JumpStart to restrict discoverable FMs.": "구성 Amazon SageMaker JumpStart to restrict discoverable FMs.",
  "Configure SageMaker to use S3 Glacier Deep Archive.": "SageMaker를 구성하여 S3 Glacier Deep Archive 사용",
  "Configure SageMaker to use a VPC with an S3 endpoint.": "SageMaker를 구성하여 S3 엔드포인트가 있는 VPC 사용",
  "Configure model invocation logging in Amazon EventBridge.": "구성 model invocation logging in Amazon EventBridge.",
  "Configure the application to automatically add 㑃make your response deterministic㑃 at the beginning of the prompt before submitting the prompt to the LLM.": "애플리케이션을 구성하여 LLM에 프롬프트를 제출하기 전에 프롬프트 시작 부분에 '응답을 결정적으로 만들기'를 자동으로 추가",
  "Configure the application to automatically add 㑃make your response deterministic㑃 at the end of the prompt before submitting the prompt to the LLM.": "애플리케이션을 구성하여 LLM에 프롬프트를 제출하기 전에 프롬프트 끝에 '응답을 결정적으로 만들기'를 자동으로 추가",
  "Configure the application to automatically set the temperature parameter to 0 when submitting the prompt to the LLM.": "애플리케이션을 구성하여 프롬프트를 LLM에 제출할 때 온도 파라미터를 자동으로 0으로 설정",
  "Configure the application to automatically set the temperature parameter to 1 when submitting the prompt to the LLM.": "애플리케이션을 구성하여 프롬프트를 LLM에 제출할 때 온도 파라미터를 자동으로 1로 설정",
  "Configure the security and compliance by using Amazon Inspector.": "Amazon Inspector를 사용하여 보안 및 규정 준수 구성",
  "Confirmation bias": "확증 편향",
  "Confusion matrix": "혼동 행렬",
  "Content filters": "콘텐츠 필터",
  "Content generation": "콘텐츠 생성",
  "Content moderation guidelines": "콘텐츠 조정 가이드라인",
  "Context window": "컨텍스트 윈도우",
  "Continued pre-training": "Continued pre-학습",
  "Continuous pre-training": "Continuous pre-학습",
  "Continuous pre-training 24": "Continuous pre-학습 24",
  "Continuously monitor the models performance on a static test dataset": "정적 테스트 데이터셋에서 모델 성능을 지속적으로 모니터링",
  "Convert audio files to text documents by using ML models.": "ML 모델을 사용하여 오디오 파일을 텍스트 문서로 변환",
  "Corporate social responsibility": "기업의 사회적 책임",
  "Correlation matrix": "상관 행렬",
  "Cost for each customer conversation": "각 고객 대화당 비용",
  "Cost of training AI models": "Cost of 학습 AI models",
  "Cost optimization": "비용 최적화",
  "Count the number of layers in the neural network.": "신경망의 레이어 수 계산",
  "Create Amazon SageMaker Model Cards with intended uses and training and inference details. 34": "의도된 사용 및 학습 및 추론 세부 정보와 함께 Amazon SageMaker Model Cards 생성",
  "Create a Python application by using Amazon Q Developer.": "Amazon Q Developer를 사용하여 Python 애플리케이션 생성",
  "Create a Retrieval Augmented Generation (RAG) workflow by using Amazon Bedrock Knowledge Bases.": "Amazon Bedrock Knowledge Bases를 사용하여 검색 증강 생성(RAG) 워크플로우 생성",
  "Create a classification model that categorizes medications into different groups by using Amazon SageMaker.": "Amazon SageMaker를 사용하여 약물을 다른 그룹으로 분류하는 분류 모델 생성",
  "Create a deep neural network by using the images as input.": "이미지를 입력으로 사용하는 딥 신경망 생성",
  "Create a different ML model for each demographic group.": "각 인구 통계 그룹에 대해 다른 ML 모델 생성",
  "Create a fraud forecasting system.": "사기 예측 시스템 생성",
  "Create a guardrail for the agent that includes the examples.": "예제를 포함하는 에이전트용 가드레일 생성",
  "Create a natural language processing (NLP) named entity recognition system.": "자연어 처리(NLP) 명명된 개체 인식 시스템 생성",
  "Create a prompt template that teaches the LLM to detect attack patterns.": "LLM이 공격 패턴을 감지하도록 가르치는 프롬프트 템플릿 생성",
  "Create a recommendation engine.": "추천 엔진 생성.",
  "Create a standard prompt template. Use Amazon Q Business to illustrate stories.": "Amazon Q Business",
  "Create a time-series forecasting model to analyze the medication reviews by using Amazon Personalize. 42": "Amazon Personalize를 사용하여 약물 리뷰를 분석하는 시계열 예측 모델 생성",
  "Create an AWS Lambda function to perform the transformations.": "변환을 수행하는 AWS Lambda 함수 생성",
  "Create an Amazon Bedrock fine-tuning job.": "Amazon Bedrock 파인튜닝 작업 생성",
  "Create an Amazon Bedrock knowledge base.": "Amazon Bedrock 지식 베이스 생성",
  "Create an Amazon SageMaker HyperPod pre-training job.": "Create an Amazon SageMaker HyperPod pre-학습 job.",
  "Create classification labels by using Amazon Comprehend.": "Amazon Comprehend를 사용하여 분류 라벨 생성",
  "Create documents with the relevant information. Store the documents in Amazon S3.": "관련 정보가 포함된 문서 생성. 문서를 Amazon S3에 저장",
  "Create effective prompts that provide clear instructions and context to guide the model㑄s generation.": "모델의 생성을 안내하기 위해 명확한 지시사항과 컨텍스트를 제공하는 효과적인 프롬프트 생성",
  "Create few-shot prompts to instruct the model to answer only domain knowledge.": "모델이 도메인 지식만 답하도록 지시하는 few-shot 프롬프트 생성",
  "Create medication review summaries by using Amazon Bedrock large language models (LLMs).": "Amazon Bedrock 대형 언어 모델(LLM)을 사용하여 약물 리뷰 요약 생성",
  "Create medication review summaries by using Amazon Rekognition.": "Amazon Rekognition을 사용하여 약물 리뷰 요약 생성",
  "Create model training scripts. Commit the model training scripts to a Git repository.": "모델 학습 스크립트 생성. 모델 학습 스크립트를 Git 저장소에 커밋",
  "Create one prompt that covers all products. Edit the responses to make the responses more specific, concise, and tailored to each product.": "모든 제품을 포함하는 하나의 프롬프트 생성. 응답을 더 구체적이고 간결하며 각 제품에 맞게 만들도록 응답 편집",
  "Create pairs of questions and answers that specifically address topics related to the company㑄s industry domain.": "회사의 업계 도메인과 관련된 주제를 구체적으로 다루는 질문 및 답변 쌍 생성",
  "Create prompts for each product category that highlight the key features. Include the desired output format and length for each prompt response.": "주요 기능을 강조하는 각 제품 카테고리에 대한 프롬프트 생성. 각 프롬프트 응답에 대한 원하는 출력 형식 및 길이 포함",
  "Create software snippets, reference tracking, and open source license tracking.": "소프트웨어 스니펫, 참조 추적 및 오픈 소스 라이선스 추적 생성",
  "Creating photorealistic images from text descriptions for digital marketing": "디지털 마케팅을 위한 텍스트 설명에서 사실적 이미지 생성",
  "Creation of the search index": "검색 인덱스 생성",
  "Crowd-sourced evaluation": "크라우드 소싱 평가",
  "Customer satisfaction score (CSAT)": "고객 만족도 점수 (CSAT)",
  "Customize the model by using fine-tuning.": "파인튜닝을 사용하여 모델 사용자 정의",
  "Data augmentation": "데이터 증강",
  "Data augmentation by using an Amazon Bedrock knowledge base": "Amazon Bedrock 지식 베이스를 사용한 데이터 증강",
  "Data augmentation for imbalanced classes": "불균형 클래스에 대한 데이터 증강",
  "Data balancing": "데이터 균형 조정",
  "Data collection": "데이터 수집",
  "Data de-identification": "데이터 비식별화",
  "Data discoverability": "데이터 발견 가능성",
  "Data encoding": "데이터 인코딩",
  "Data enrichment": "데이터 풍부화",
  "Data governance": "데이터 거버넌스",
  "Data labeling": "데이터 라벨링",
  "Data leakage": "데이터 누출",
  "Data mining": "데이터 마이닝",
  "Data normalization": "데이터 정규화",
  "Data pre-processing": "데이터 전처리",
  "Data preprocessing": "데이터 전처리",
  "Data protection": "데이터 보호",
  "Data quality": "데이터 품질",
  "Data quality standards": "데이터 품질 표준",
  "Data residency": "데이터 거주지",
  "Data retention": "데이터 보존",
  "Data selection": "데이터 선택",
  "Data summarization by using Amazon QuickSight Q": "Amazon QuickSight Q를 사용한 데이터 요약",
  "Decision tree": "의사결정 나무",
  "Decision trees": "의사결정 나무",
  "Decrease the Top K value.": "Top K 값 감소",
  "Decrease the batch size.": "배치 크기 감소.",
  "Decrease the epochs.": "에폭 감소.",
  "Decrease the length of output tokens.": "출력 토큰 길이 감소",
  "Decrease the number of epochs.": "에폭 수 감소.",
  "Decrease the number of input tokens on invocations of the LLM.": "LLM 호출 시 입력 토큰 수 감소.",
  "Decrease the number of tokens in the prompt.": "프롬프트의 토큰 수 증가",
  "Decrease the prompt length.": "프롬프트 길이 감소",
  "Decrease the regularization parameter to increase model complexity.": "모델 복잡성을 높이기 위해 정규화 파라미터 감소",
  "Decrease the temperature inference parameter for the model.": "모델의 온도 추론 파라미터 감소",
  "Decrease the temperature value.": "온도 값 감소",
  "Decrease the token size.": "토큰 크기 감소",
  "Decreases the training time requirement": "감소s the training time requirement",
  "Deep learning model": "딥러닝 모델",
  "Deep learning model built on principal components": "주성분에 구축된 딥러닝 모델",
  "Define a higher number for the temperature parameter.": "온도 파라미터에 더 높은 값 정의.",
  "Delete the custom model. Remove the confidential data from the training dataset. Retrain the custom model.": "사용자 정의 모델 삭제. 학습 데이터셋에서 기밀 데이터 제거. 사용자 정의 모델 재학습",
  "Denial of service (DoS)": "서비스 거부 (DoS)",
  "Denied topics": "거부된 주제",
  "Deploy a custom model on Amazon Bedrock.": "Amazon Bedrock에 사용자 정의 모델 배포",
  "Deploy optimized large language models (LLMs) on edge devices.": "엣지 디바이스에 최적화된 대형 언어 모델(LLM) 배포.",
  "Deploy optimized small language models (SLMs) on edge devices.": "엣지 디바이스에 최적화된 소형 언어 모델(SLM) 배포.",
  "Deploy the custom model in an Amazon SageMaker endpoint for real-time inference.": "Deploy the custom model in an Amazon SageMaker endpoint for 실시간 추론.",
  "Deploy the model by using Amazon CloudFront with an Amazon S3 integration.": "Amazon S3 통합과 함께 Amazon CloudFront를 사용하여 모델 배포",
  "Deploy the model by using an Amazon EC2 compute optimized instance.": "Amazon EC2 컴퓨팅 최적화 인스턴스를 사용하여 모델 배포",
  "Deploy the model by using an Amazon SageMaker endpoint. 45": "Amazon SageMaker 엔드포인트를 사용하여 모델 배포",
  "Deploy the model on an Amazon EC2 instance.": "Amazon EC2 인스턴스에 모델 배포",
  "Deploy the model on an Amazon Elastic Kubernetes Service (Amazon EKS) cluster.": "Amazon Elastic Kubernetes Service (Amazon EKS) 클러스터에 모델 배포",
  "Deployment": "배포",
  "Deployment time": "배포 시간",
  "Design clear and specific prompts. Configure AWS Identity and Access Management (IAM) roles and policies by using least privilege access.": "명확하고 구체적인 프롬프트 설계. 최소 권한 액세스를 사용하여 AWS Identity and Access Management (IAM) 역할 및 정책 구성",
  "Designing an agent avatar that looks like a computer": "컴퓨터처럼 보이는 에이전트 아바타 설계",
  "Detect imbalances or disparities in the data.": "데이터의 불균형 또는 불일치 감지",
  "Develop a Retrieval Augmented Generation (RAG) agent by using Amazon Bedrock.": "Amazon Bedrock을 사용하여 검색 증강 생성(RAG) 에이전트 개발",
  "Develop a multi-language translation system.": "다국어 번역 시스템 개발.",
  "Develop a summarization chatbot.": "요약 챗봇 개발.",
  "Develop an anomaly detection system.": "Develop an 이상 탐지 system.",
  "Develop an interactive UI for customers and provide clear technical explanations about the system.": "고객을 위한 대화형 UI 개발 및 시스템에 대한 명확한 기술 설명 제공",
  "Develop multiple regex patterns to detect sensitive data. Expose the regex patterns on an Amazon SageMaker notebook.": "민감한 데이터를 감지하기 위한 여러 정규식 패턴 개발. Amazon SageMaker 노트북에서 정규식 패턴 노출",
  "Developing policies and guidelines for data, transparency, responsible AI, and compliance": "데이터, 투명성, 책임 있는 AI 및 규정 준수를 위한 정책 및 가이드라인 개발",
  "Dialog 34": "대화",
  "Diffusion": "확산",
  "Diffusion model": "확산 모델",
  "Direction": "방향",
  "Directional stimulus prompting": "방향성 자극 프롬프팅",
  "Distillation": "증류",
  "Diverse conversations that use relevant terminology": "관련 용어를 사용하는 다양한 대화",
  "Diversity": "다양성",
  "Documents critical details about ML models": "ML 모델에 대한 중요한 세부 정보 문서화",
  "Download AWS security and compliance documents from AWS Artifact.": "AWS Artifact에서 AWS 보안 및 규정 준수 문서 다운로드",
  "Embeddings": "임베딩",
  "Embeddings is a technique that searches data to find the most helpful information to answer natural language questions.": "임베딩은 자연어 질문에 답하기 위해 가장 유용한 정보를 찾기 위해 데이터를 검색하는 기법입니다",
  "Embeddings provide the ability to store and retrieve data for generative AI applications.": "임베딩은 생성형 AI 애플리케이션을 위한 데이터 저장 및 검색 기능을 제공합니다",
  "Embeddings reduce the hardware requirements of a model by using a less precise data type for the weights and activations.": "임베딩은 가중치 및 활성화에 덜 정밀한 데이터 타입을 사용하여 모델의 하드웨어 요구사항을 감소시킵니다",
  "Embeddings represent data as high-dimensional vectors that capture semantic relationships.": "임베딩은 의미 관계를 포착하는 고차원 벡터로 데이터를 표현합니다",
  "Employing a chatbot to provide human-like responses to customer queries in real time": "고객 쿼리에 실시간으로 인간과 같은 응답을 제공하는 챗봇 사용",
  "Enable AWS Audit Manager for automatic model evaluation jobs.": "자동 모델 평가 작업을 위해 AWS Audit Manager 활성화",
  "Enable Amazon Bedrock automatic model evaluation jobs.": "Amazon Bedrock 자동 모델 평가 작업 활성화",
  "Enable invocation logging in Amazon Bedrock.": "Amazon Bedrock에서 호출 로깅 활성화",
  "Enable model invocation logging.": "모델 호출 로깅 활성화",
  "Enable voice commands for coding and providing natural language search.": "코딩 및 자연어 검색 제공을 위한 음성 명령 활성화",
  "Encrypt and secure training data by using Amazon Macie.": "Amazon Macie를 사용하여 학습 데이터 암호화 및 보안",
  "Encrypt the confidential data in the custom model by using AWS Key Management Service (AWS KMS).": "AWS Key Management Service (AWS KMS)를 사용하여 사용자 정의 모델의 기밀 데이터 암호화",
  "Encrypt the confidential data in the inference responses by using Amazon SageMaker.": "Amazon SageMaker를 사용하여 추론 응답의 기밀 데이터 암호화",
  "Encrypt the data at rest by using encryption for SageMaker geospatial capabilities.": "SageMaker 지리 공간 기능에 대한 암호화를 사용하여 저장 데이터 암호화",
  "Energy efficiency of the models computations": "모델 계산의 에너지 효율",
  "Enhancing database performance by using optimized indexing": "최적화된 인덱싱을 사용한 데이터베이스 성능 향상",
  "Ensure that the ML model predictions are consistent with historical results.": "ML 모델 예측이 과거 결과와 일관되도록 보장",
  "Ensure that the S3 data does not contain sensitive information.": "S3 데이터에 민감한 정보가 포함되지 않도록 보장.",
  "Ensure that the data is balanced and collected from a diverse group.": "데이터가 균형 잡혀 있고 다양한 그룹에서 수집되도록 보장",
  "Ensure that the data is from a publicly available dataset.": "데이터가 공개적으로 사용 가능한 데이터셋에서 온 것인지 보장",
  "Ensure that the model runs frequently.": "모델이 자주 실행되도록 보장",
  "Ensure that the models inference time is within the accepted limits.": "모델의 추론 시간이 허용된 한도 내에 있도록 보장",
  "Ensure that the role that Amazon Bedrock assumes has permission to decrypt data with the correct encryption key.": "Amazon Bedrock이 가정하는 역할이 데이터 복호화 권한을 갖도록 설정",
  "Ensuring alignment with business standards, revenue goals, and stakeholder expectations": "비즈니스 표준, 수익 목표 및 이해관계자 기대와의 정렬 보장",
  "Evaluate the models by using a human workforce and custom prompt datasets.": "인력과 사용자 정의 프롬프트 데이터셋을 사용하여 모델 평가",
  "Evaluate the models by using built-in prompt datasets.": "내장 프롬프트 데이터셋을 사용하여 모델 평가",
  "Evaluate the model㑄s behavior so that the company can provide transparency to stakeholders.": "회사가 이해관계자에게 투명성을 제공할 수 있도록 모델의 동작 평가",
  "Evaluate the model㑄s performance on benchmark datasets.": "벤치마크 데이터셋에서 모델 성능 평가",
  "Evaluation": "모델이 100% 정확하도록 보장하기 위해 요약 평가를 위한 재현율 지향 보조(ROUGE) 기법 사용",
  "Expanding initiatives across business units to create long-term business value": "장기적인 비즈니스 가치를 창출하기 위해 비즈니스 단위 전반에 걸쳐 이니셔티브 확장",
  "Experiment and refine the prompt until the FM produces the desired responses.": "프롬프트를 실험하고 개선하여 FM이 원하는 응답을 생성하도록 함",
  "Explainability": "설명 가능성",
  "Exploiting friendliness and trust": "친절함과 신뢰 악용",
  "Exploratory data analysis": "탐색적 데이터 분석",
  "Extract information from call recordings by using Amazon SageMaker Model Monitor.": "Amazon SageMaker Model Monitor를 사용하여 통화 녹음에서 정보 추출",
  "Extracting the prompt template": "프롬프트 템플릿 추출",
  "F1 score": "F1 점수",
  "F1 score 19": "F1 점수 19",
  "Fairness": "공정성",
  "Feature engineering": "특성 엔지니어링",
  "Federated learning": "연합 학습",
  "Few-shot prompting": "Few-shot 프롬프팅 (소수 샘플 프롬프팅)",
  "Financial cost of operating the model": "모델 운영의 재정적 비용",
  "Fine-tune an LLM on the company policy text by using Amazon SageMaker.": "Amazon SageMaker를 사용하여 회사 정책 텍스트로 LLM 파인튜닝",
  "Fine-tune models on Amazon SageMaker Jumpstart.": "Amazon SageMaker JumpStart",
  "Fine-tune the FM to avoid harmful responses.": "유해한 응답을 피하기 위해 FM 파인튜닝",
  "Fine-tune the FM.": "FM 파인튜닝",
  "Fine-tune the LLM on the company policy data.": "Amazon SageMaker를 사용하여 회사 정책 텍스트로 LLM 파인튜닝",
  "Fine-tune the model by using additional training data that is representative of the various age ranges that the application will support.": "애플리케이션이 지원할 다양한 연령대를 대표하는 추가 학습 데이터를 사용하여 모델 파인튜닝",
  "Fine-tune the model regularly.": "모델을 정기적으로 파인튜닝",
  "Fine-tuning": "파인튜닝은 FM의 크기와 복잡성을 감소시키고 더 느린 추론을 가능하게 합니다",
  "Fine-tuning improves the performance of the FM on a specific task by further training the FM on new labeled data.": "파인튜닝은 새 라벨 데이터에서 FM을 추가로 학습시켜 특정 작업에서 FM의 성능을 향상시킵니다",
  "Fine-tuning keeps the FM㑄s knowledge up to date by pre-training the FM on more recent data.": "파인튜닝은 더 최근 데이터에서 FM을 사전 학습시켜 FM의 지식을 최신 상태로 유지합니다",
  "Fine-tuning reduces the FM㑄s size and complexity and enables slower inference.": "파인튜닝은 FM의 크기와 복잡성을 감소시키고 더 느린 추론을 가능하게 합니다",
  "Fine-tuning uses specific training data to retrain the FM from scratch to adapt to a specific use case.": "파인튜닝은 특정 사용 사례에 적응하기 위해 처음부터 FM을 재학습하기 위해 특정 학습 데이터를 사용합니다",
  "Flexibility": "유연성",
  "Forecasting revenue for certain products": "특정 제품에 대한 수익 예측",
  "Fraud detection": "사기 탐지",
  "Full training 34": "전체 학습",
  "Fuzzing training data to find vulnerabilities": "취약점을 찾기 위해 학습 데이터 퍼징",
  "Gambling": "도박",
  "Gather company internal documents and industry-specific materials. Merge the documents and materials into a single file.": "회사 내부 문서 및 업계별 자료 수집. 문서와 자료를 단일 파일로 병합",
  "Gather historical patient readmission data.": "과거 환자 재입원 데이터 수집",
  "Gather more data. Use Amazon Rekognition to add custom labels to the data.": "더 많은 데이터 수집. Amazon Rekognition을 사용하여 데이터에 사용자 정의 라벨 추가",
  "Generate simple metrics, reports, and examples by using Amazon SageMaker Clarify.": "Amazon SageMaker Clarify를 사용하여 간단한 메트릭, 보고서 및 예제 생성",
  "Generating human-like text based on a given prompt 18": "주어진 프롬프트를 기반으로 인간과 같은 텍스트 생성",
  "Generation of content embeddings": "콘텐츠 임베딩 생성",
  "Generation of custom foundation models (FMs) to predict customer needs 30": "고객 니즈 예측을 위한 사용자 정의 파운데이션 모델(FM) 생성",
  "Generation of embeddings for user queries": "사용자 쿼리용 임베딩 생성",
  "Generation step": "생성 단계",
  "Generative adversarial network (GAN)": "생성적 적대 신경망(GAN)",
  "Generative pre-trained transformers (GPT)": "생성형 사전 훈련 트랜스포머(GPT)",
  "Geolocation routing": "지리적 위치 라우팅",
  "Give users the ability to interact based on user preferences.": "사용자 선호도에 따라 상호작용할 수 있는 기능을 사용자에게 제공",
  "Governance": "거버넌스",
  "Grant access to the custom model in Amazon Bedrock. 19": "Amazon Bedrock의 사용자 정의 모델에 액세스 권한 부여",
  "Grouping a set of characters to be treated as a single unit": "단일 단위로 처리될 문자 집합 그룹화",
  "Guardrails for Amazon Bedrock": "Amazon Bedrock용 Guardrails",
  "Hallucination": "환각",
  "Hallucinations": "환각",
  "Hate": "혐오",
  "Helps decrease the model㑄s complexity": "모델의 복잡성 감소에 도움",
  "Host the Amazon Bedrock API on premises.": "프레미스에서 Amazon Bedrock API 호스팅",
  "Host the model by using Amazon SageMaker. Use TensorRT for large language model (LLM) deployment.": "Amazon SageMaker를 사용하여 모델 호스팅. 대형 언어 모델(LLM) 배포를 위해 TensorRT 사용",
  "Host the model on premises by using AWS Outposts.": "AWS Outposts를 사용하여 프레미스에서 모델 호스팅",
  "Human-in-the-loop": "인간 개입 (Human-in-the-loop)",
  "Human-in-the-loop validation by using Amazon SageMaker Ground Truth Plus": "Amazon SageMaker Ground Truth Plus를 사용한 인간 개입 검증",
  "Hyperparameter tuning": "하이퍼파라미터 튜닝",
  "IaC always provisions powerful compute instances, contributing to the training of more accurate models.": "IaC는 항상 강력한 컴퓨팅 인스턴스를 프로비저닝하여 더 정확한 모델 학습에 기여",
  "IaC eliminates the need for hyperparameter tuning.": "IaC는 하이퍼파라미터 튜닝의 필요성을 제거",
  "IaC minimizes overall expenses by deploying only low-cost instances.": "IaC는 저비용 인스턴스만 배포하여 전체 비용 최소화",
  "IaC streamlines the deployment of scalable and consistent ML workloads in cloud environments.": "IaC는 클라우드 환경에서 확장 가능하고 일관된 ML 워크로드 배포를 간소화",
  "Identifies potential bias during data preparation": "데이터 준비 중 잠재적 편향 식별",
  "Ignoring the prompt template": "프롬프트 템플릿 무시",
  "Image data": "이미지 데이터",
  "Image generation model": "이미지 생성 모델",
  "Image processing": "이미지 처리",
  "Image recognition by using Amazon Rekognition": "Amazon Rekognition을 사용한 이미지 인식",
  "Immediately start training a custom FM by using the company㑄s existing data.": "회사의 기존 데이터를 사용하여 사용자 정의 FM 학습 즉시 시작",
  "Implement Amazon Kendra to provide a searchable index for medical records. Use a template-based system to format summaries.": "Amazon Kendra를 구현하여 의료 기록에 대한 검색 가능한 인덱스 제공. 템플릿 기반 시스템을 사용하여 요약 형식 지정",
  "Implement Amazon SageMaker Model Monitor to detect data drift and receive alerts when model quality degrades.": "Amazon SageMaker Model Monitor를 구현하여 데이터 드리프트 감지 및 모델 품질 저하 시 알림 수신",
  "Implement Retrieval Augmented Generation (RAG) for in-context responses.": "컨텍스트 내 응답을 위한 검색 증강 생성(RAG) 구현",
  "Implement a prebuilt AI assistant solution and measure its impact on customer satisfaction.": "사전 구축된 AI 어시스턴트 솔루션 구현 및 고객 만족도에 대한 영향 측정",
  "Implement moderation APIs.": "조정 API 구현",
  "Implementing a rule-based recommendation engine to suggest products to customers": "고객에게 제품을 추천하는 규칙 기반 추천 엔진 구현",
  "Import the data into Amazon SageMaker Canvas. Build ML models and demand forecast predictions by selecting the values in the data from SageMaker Canvas.": "데이터를 Amazon SageMaker Canvas로 가져오기. SageMaker Canvas의 데이터에서 값을 선택하여 ML 모델 및 수요 예측 구축",
  "Import the data into Amazon SageMaker Data Wrangler. Build ML models and demand forecast predictions by using an Amazon Personalize Trending-Now recipe.": "데이터를 Amazon SageMaker Data Wrangler로 가져오기. Amazon Personalize Trending-Now 레시피를 사용하여 ML 모델 및 수요 예측 구축",
  "Import the data into Amazon SageMaker Data Wrangler. Create ML models and demand forecast predictions by using SageMaker built-in algorithms.": "데이터를 Amazon SageMaker Data Wrangler로 가져오기. SageMaker 내장 알고리즘을 사용하여 ML 모델 및 수요 예측 생성",
  "Improves model performance over time": "시간이 지남에 따라 모델 성능 향상",
  "Improving network security by using intrusion detection systems": "침입 탐지 시스템을 사용한 네트워크 보안 향상",
  "Include a diverse range of product features in each prompt to generate creative and unique descriptions.": "창의적이고 독특한 설명을 생성하기 위해 각 프롬프트에 다양한 제품 기능 포함",
  "Include fairness metrics for model evaluation.": "모델 평가를 위한 공정성 메트릭 포함",
  "Include more diverse training data. Fine-tune the model again by using the new data.": "Include more diverse training data. 모델 파인튜닝 again by using the new data.",
  "Including referenced product manual links in the response": "응답에 참조된 제품 매뉴얼 링크 포함",
  "Incorporate a centralized large language model (LLM) API for asynchronous communication with edge devices.": "엣지 디바이스와 비동기 통신을 위한 중앙화된 대형 언어 모델(LLM) API 통합",
  "Incorporate a centralized small language model (SLM) API for asynchronous communication with edge devices.": "엣지 디바이스와 비동기 통신을 위한 중앙화된 소형 언어 모델(SLM) API 통합",
  "Increase the Top K value.": "Top K 값 증가.",
  "Increase the accuracy of the model to reduce the need for transparency.": "투명성 필요를 줄이기 위해 모델 정확도 증가",
  "Increase the classifier-free guidance (CFG) scale.": "분류기 없는 가이던스(CFG) 스케일 증가",
  "Increase the epochs.": "에폭 감소",
  "Increase the maximum generation length.": "최대 생성 길이 증가",
  "Increase the model training time.": "Increase the model 학습 time.",
  "Increase the model㑄s complexity by adding more layers to the model㑄s architecture.": "모델 아키텍처에 더 많은 레이어를 추가하여 모델의 복잡성 증가",
  "Increase the number of epochs.": "에폭 수 증가.",
  "Increase the number of generation steps.": "생성 단계 수 증가",
  "Increase the number of tokens in the prompt.": "프롬프트의 토큰 수 증가",
  "Increase the prompt strength.": "프롬프트 강도 증가",
  "Increase the regularization parameter to decrease model complexity.": "모델 복잡성을 감소시키기 위해 정규화 파라미터 증가",
  "Increase the response length.": "응답 길이 증가",
  "Increase the temperature parameter on invocation requests to the LLM.": "온도 증가 parameter on invocation requests to the LLM.",
  "Increase the temperature parameter.": "온도 증가 parameter.",
  "Increase the temperature value.": "온도 증가 value.",
  "Increase the temperature.": "온도 증가.",
  "Increase the volume of data that is used in training.": "Increase the volume of data that is used in 학습.",
  "Inference": "추론",
  "Inference speed": "추론 speed",
  "Innovation speed": "혁신 속도",
  "Inpainting": "인페인팅",
  "Install a code forecasting tool to predict potential code issues.": "잠재적 코드 문제를 예측하는 코드 예측 도구 설치",
  "Install code recommendation software in the company㑄s developer tools.": "회사의 개발자 도구에 코드 추천 소프트웨어 설치",
  "Instruction following model": "지시 따르기 모델",
  "Integrates a Retrieval Augmented Generation (RAG) workflow": "검색 증강 생성(RAG) 워크플로우 통합",
  "Integration with Amazon S3 for object storage": "객체 스토리지를 위한 Amazon S3 통합",
  "Internet gateway": "인터넷 게이트웨이",
  "Jailbreak": "재일브레이크",
  "K-mean": "K-평균",
  "K-means": "K-평균",
  "K-means algorithm": "K-평균 알고리즘",
  "K-nearest neighbors (k-NN)": "K-최근접 이웃 (k-NN)",
  "K-nearest neighbors (k-NN) model": "K-최근접 이웃 (k-NN) 모델",
  "Keep the model㐴s decision-making process a secret to protect proprietary algorithms.": "독점 알고리즘을 보호하기 위해 모델의 의사결정 과정을 비밀로 유지",
  "Knowledge Bases": "지식 베이스",
  "Large language model (LLM) hallucinations": "대형 언어 모델(LLM) 환각",
  "Large multi-modal language model": "대규모 멀티모달 언어 모델",
  "Latency": "지연 시간",
  "Latency of the text generation": "텍스트 생성의 지연 시간",
  "Latent training": "Latent 학습",
  "Learning rate": "학습률",
  "Least-to-most prompting": "최소-최대 프롬프팅",
  "Less sensitivity to changes in inputs": "입력 변경에 대한 민감도 감소",
  "Lift chart": "리프트 차트",
  "Linear regression": "선형 회귀",
  "Local algorithm accountability laws": "지역 알고리즘 책임 법률",
  "Local education privacy laws": "지역 교육 개인정보 보호 법률",
  "Local health data protection laws": "지역 건강 데이터 보호 법률",
  "Local payment card data protection laws": "지역 결제 카드 데이터 보호 법률",
  "Log storage": "로그 저장",
  "Logistic regression": "로지스틱 회귀",
  "Logistic regression model": "로지스틱 회귀 model",
  "Loosely coupled microservices": "느슨하게 결합된 마이크로서비스",
  "Machine translation": "기계 번역",
  "Mask the confidential data in the inference responses by using dynamic data masking.": "동적 데이터 마스킹을 사용하여 추론 응답의 기밀 데이터 마스킹",
  "Maximum tokens": "최대 토큰",
  "Mean squared error (MSE)": "평균 제곱 오차 (MSE)",
  "Measure class imbalance on the training dataset. Adapt the training process accordingly.": "학습 데이터셋의 클래스 불균형 측정. 그에 따라 학습 프로세스 조정",
  "Measure the computational resources required for model deployment.": "Measure the computational resources required for 모델 배포.",
  "Measure the models accuracy against a predefined benchmark dataset.": "사전 정의된 벤치마크 데이터셋에 대해 모델의 정확도 측정",
  "Measurement bias": "측정 편향",
  "Modality": "모달리티",
  "Model checkpoint": "모델 체크포인트",
  "Model complexity": "모델 복잡성",
  "Model convergence tables": "모델 수렴 테이블",
  "Model customization": "모델 사용자 정의",
  "Model deployment": "모델 배포",
  "Model evaluation with human workers": "인력이 있는 모델 평가",
  "Model interoperability": "모델 상호 운용성",
  "Model interpretability": "모델 해석 가능성",
  "Model monitoring for class distribution": "클래스 분포 모니터링",
  "Model performance": "모델 성능",
  "Model precision and recall": "Model 정밀도 and recall",
  "Model quantization": "모델 양자화",
  "Model size": "모델 크기",
  "Model size and resource requirements": "모델 크기 및 리소스 요구사항",
  "Model speed in generating responses": "응답 생성의 모델 속도",
  "Model training": "Model 학습",
  "Models": "모델",
  "Moderation logs": "조정 로그",
  "Modify the AI assistant㑄s conversational style to use more formal language and include technical product specifications.": "AI 어시스턴트의 대화 스타일을 더 공식적인 언어를 사용하고 기술적 제품 사양을 포함하도록 수정",
  "Modify the advanced prompts for the agent to include the examples.": "예제를 포함하도록 에이전트의 고급 프롬프트 수정",
  "Modify the training data to mitigate bias.": "편향을 완화하기 위해 학습 데이터 수정",
  "Monitors the quality of ML models in production": "프로덕션에서 ML 모델의 품질 모니터링",
  "Multi-class classification": "다중 클래스 분류",
  "Multi-modal": "멀티모달",
  "Multi-modal embedding model": "멀티모달 임베딩 모델",
  "Multi-modal generation model": "멀티모달 생성 모델",
  "Multimodality": "멀티모달리티",
  "Named entity recognition": "명명된 개체 인식",
  "Natural language processing (NLP)": "자연어 처리 (NLP)",
  "Natural language understanding accuracy rates": "Natural language understanding 정확도 rates",
  "Neural network": "신경망",
  "Neural networks 2": "신경망 2",
  "Nondeterminism": "비결정론",
  "Nova Canvas": "중간 이미지를 생성하기 위해 Amazon Bedrock의 Amazon Nova Canvas 모델 사용. 비디오를 생성하기 위해 비디오 편집 소프트웨어 사용",
  "Nova Lite": "Nova Lite",
  "Nova Pro": "Nova Pro",
  "Nova Reel": "Nova Reel",
  "Number of customer inquiries handled": "처리된 고객 문의 수",
  "Number of hyperparameters": "하이퍼파라미터 수",
  "Number of tokens consumed": "소비된 토큰 수",
  "Number of training instances": "Number of 학습 instances",
  "Object detection": "객체 탐지",
  "Observer bias": "관찰자 편향",
  "On-Demand": "온디맨드",
  "One-shot prompting": "원샷 프롬프팅",
  "Open source": "오픈 소스",
  "Open-ended generation": "개방형 생성",
  "Optimize the model㑄s architecture and hyperparameters to improve the model㑄s overall performance.": "모델의 아키텍처와 하이퍼파라미터를 최적화하여 모델의 전반적인 성능 향상",
  "Optimizer type 9": "옵티마이저 유형",
  "Optimizes model inference time": "모델 추론 시간 최적화",
  "Overcoming challenges to drive business transformation and growth": "비즈니스 변혁과 성장을 촉진하기 위한 도전 과제 극복",
  "Overfitting": "과적합",
  "Pairs of chatbot responses and correct user intents": "챗봇 응답 및 정확한 사용자 의도 쌍",
  "Pairs of user intents and correct chatbot responses": "사용자 의도 및 정확한 챗봇 응답 쌍",
  "Pairs of user messages and correct chatbot responses": "사용자 메시지 및 정확한 챗봇 응답 쌍",
  "Pairs of user messages and correct user intents": "사용자 메시지 및 정확한 사용자 의도 쌍",
  "Partial dependence plots (PDPs)": "부분 의존성 플롯 (PDPs)",
  "PartyRock, an Amazon Bedrock Playground": "Amazon Bedrock Playground",
  "Patching and updating the versions of Amazon Bedrock": "Amazon Bedrock 버전 패치 및 업데이트",
  "Penetration testing with authorization": "승인된 침투 테스트",
  "Perform model validation.": "모델 검증 수행",
  "Physically storing models for archival purposes.": "보관 목적으로 모델을 물리적으로 저장",
  "Plagiarism": "표절",
  "Politics": "정치",
  "Pre-train a new LLM with more diverse training data.": "Pre-train a new LLM with more diverse 학습 data.",
  "Pre-train and benchmark the model by using context data.": "Pre-학습 and benchmark the model by using context data.",
  "Pre-training": "Pre-학습",
  "Pre-training bias": "Pre-학습 bias",
  "Precision": "정밀도",
  "Predictability of outputs": "출력의 예측 가능성",
  "Predicting the price of a house based on the house㐴s features": "집의 특성을 기반으로 집 가격 예측",
  "Prepare the training dataset by creating a .txt file that contains multiple lines in .csv format.": ".csv 형식의 여러 줄을 포함하는 .txt 파일을 만들어 학습 데이터셋 준비",
  "Prescriptive ML models": "처방형 ML 모델",
  "Present the model Shapley values.": "모델 Shapley 값 제시",
  "Privacy": "개인정보 보호",
  "Privacy and security": "개인정보 보호 및 보안",
  "Prompt": "프롬프트",
  "Prompt Management": "프롬프트 관리",
  "Prompt chaining": "프롬프트 체이닝",
  "Prompt engineering could expose the model to vulnerabilities such as prompt injection attacks.": "프롬프트 엔지니어링은 프롬프트 인젝션 공격과 같은 취약점에 모델을 노출시킬 수 있습니다",
  "Prompt engineering does not ensure that the model always produces consistent and deterministic outputs, eliminating the need for validation.": "프롬프트 엔지니어링은 모델이 항상 일관되고 결정론적인 출력을 생성한다는 것을 보장하지 않으며, 검증의 필요성을 제거하지 않습니다",
  "Prompt engineering does not ensure that the model will consistently generate highly reliable outputs when working with real-world data. 19": "프롬프트 엔지니어링은 실제 데이터로 작업할 때 모델이 지속적으로 매우 안정적인 출력을 생성한다는 것을 보장하지 않습니다",
  "Prompt injection": "프롬프트 인젝션",
  "Prompt templating": "프롬프트 템플릿화",
  "Prompted persona switches": "프롬프트된 페르소나 전환",
  "Properly designed prompts reduce but do not eliminate the risk of data poisoning or model hijacking.": "적절히 설계된 프롬프트는 데이터 중독 또는 모델 하이재킹의 위험을 줄이지만 제거하지는 않습니다",
  "Protecting the infrastructure that hosts Amazon Bedrock": "Amazon Bedrock을 호스팅하는 인프라 보호",
  "Provide a detailed explanation of sentiment analysis and how LLMs work in the prompt.": "프롬프트에 감정 분석 및 LLM 작동 방식에 대한 자세한 설명 제공",
  "Provide a secure model inference endpoint.": "Provide a secure model 추론 endpoint.",
  "Provide a variety of responses to select from for user engagement.": "사용자 참여를 위해 선택할 수 있는 다양한 응답 제공",
  "Provide detailed, product-specific prompts to ensure precise and customized descriptions.": "정확하고 사용자 정의된 설명을 보장하기 위해 상세하고 제품별 프롬프트 제공",
  "Provide examples of text passages with corresponding positive or negative labels in the prompt followed by the new text passage to be classified.": "프롬프트에 해당하는 긍정 또는 부정 라벨이 있는 텍스트 구절 예제 제공, 그 다음 분류할 새 텍스트 구절",
  "Provide labeled data with the prompt field and the completion field.": "프롬프트 필드와 완료 필드가 있는 라벨 데이터 제공",
  "Provide the model accuracy measure.": "Provide the model 정확도 measure.",
  "Provide the model confusion matrix.": "Provide the model 혼동 행렬.",
  "Provide the new text passage to be classified without any additional context or examples.": "추가 컨텍스트나 예제 없이 분류할 새 텍스트 구절 제공",
  "Provide the new text passage with a few examples of unrelated tasks, such as text summarization or question answering.": "텍스트 요약 또는 질문 답변과 같은 관련 없는 작업의 몇 가지 예제와 함께 새 텍스트 구절 제공",
  "Providing a visually appealing summary of a mode㐴s capabilities.": "모델의 기능에 대한 시각적으로 매력적인 요약 제공",
  "Providing the ability to mathematically compare texts": "텍스트를 수학적으로 비교하는 기능 제공",
  "Providing the count of every word in the input": "입력의 모든 단어 수 제공",
  "Provisioned Throughput": "프로비저닝된 처리량",
  "Provisioning Amazon Bedrock within the company network": "회사 네트워크 내에서 Amazon Bedrock 프로비저닝",
  "Purchase Provisioned Throughput for Amazon Bedrock.": "Amazon Bedrock의 프로비저닝된 처리량 구매",
  "Purchase Provisioned Throughput for the custom model.": "사용자 정의 모델의 프로비저닝된 처리량 구매",
  "Purchase Provisioned Throughput for the model on Amazon Bedrock.": "Amazon Bedrock의 모델에 대한 프로비저닝된 처리량 구매",
  "R-squared": "R-제곱",
  "R-squared score": "R-제곱 점수",
  "R2 score": "R2 점수",
  "RAG can use external knowledge sources to generate more accurate and informative responses.": "RAG는 외부 지식 소스를 사용하여 더 정확하고 유익한 응답을 생성할 수 있습니다",
  "RAG is a technique for data augmentation in computer vision tasks.": "RAG는 컴퓨터 비전 작업에서 데이터 증강을 위한 기법입니다",
  "RAG is designed to improve the speed of language model training.": "RAG is designed to improve the speed of language model 학습.",
  "RAG is primarily used for speech recognition tasks.": "RAG는 주로 음성 인식 작업에 사용됩니다",
  "Random cut forest algorithm": "랜덤 컷 포레스트 알고리즘",
  "Re-train the model with fresh data.": "최신 데이터로 모델 재학습.",
  "Real world knowledge (RWK) score": "실제 세계 지식 (RWK) 점수",
  "Real-time inference": "실시간 추론",
  "Reasoning and acting (ReAct) prompting": "추론 및 행동 (ReAct) 프롬프팅",
  "Recall": "모델이 100% 정확하도록 보장하기 위해 요약 평가를 위한 재현율 지향 보조(ROUGE) 기법 사용",
  "Recall-Oriented Understudy for Gisting Evaluation (ROUGE)": "모델이 100% 정확하도록 보장하기 위해 요약 평가를 위한 재현율 지향 보조(ROUGE) 기법 사용",
  "Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score": "요약 평가를 위한 재현율 지향 보조(ROUGE) 점수",
  "Recency bias": "최근성 편향",
  "Recommendation system": "추천 시스템",
  "Recommendation systems": "추천 시스템",
  "Reduce the size of the training dataset.": "학습 데이터셋 크기 감소",
  "Reduce the volume of data that is used in training.": "Reduce the volume of data that is used in 학습.",
  "Reducing the overall computational requirements of a model.": "모델의 전반적인 컴퓨팅 요구사항 감소",
  "Refining an existing third-party generative AI foundation model (FM) by fine-tuning the model by using data specific to the business.": "비즈니스에 특정한 데이터를 사용하여 모델을 파인튜닝하여 기존 서드파티 생성형 AI 기반 모델(FM) 정제",
  "Register the model with the Amazon SageMaker Model Registry.": "Amazon SageMaker Model Registry",
  "Regression": "회귀",
  "Regulatory compliance": "규제 준수",
  "Reinforcement learning": "강화 학습",
  "Reinforcement learning from human feedback (RLHF)": "인간 피드백으로부터의 강화 학습 (RLHF)",
  "Reinforcement learning with rewards for positive customer feedback": "긍정적인 고객 피드백에 대한 보상이 있는 강화 학습",
  "Reliability": "신뢰성",
  "Religion": "종교",
  "Residual neural network": "잔차 신경망",
  "Response generation for the user": "사용자에 대한 응답 생성",
  "Response streaming": "응답 스트리밍",
  "Restart the SageMaker AI endpoint.": "SageMaker AI 엔드포인트 재시작.",
  "Restrict access to Amazon Bedrock by using an AWS Identity and Access Management (IAM) resource policy.": "AWS Identity and Access Management (IAM) 리소스 정책을 사용하여 Amazon Bedrock에 대한 액세스 제한",
  "Restrict access to Amazon Bedrock by using an AWS Identity and Access Management (IAM) service role.": "AWS Identity and Access Management (IAM) 서비스 역할을 사용하여 Amazon Bedrock에 대한 액세스 제한",
  "Restrict user conversations to predefined topics.": "Restrict 사용r conversations to predefined topics.",
  "Retrain the FM.": "FM 재학습",
  "Retrain the LLM on the company policy data.": "회사 정책 데이터로 LLM 재학습",
  "Retrain the model with a general public dataset.": "일반 공개 데이터셋으로 모델 재학습",
  "Retrain the model. Monitor model drift by using Amazon SageMaker Clarify.": "모델 재학습. Monitor model drift by using Amazon SageMaker Clarify.",
  "Retrain the model. Monitor model drift by using Amazon SageMaker Model Monitor.": "모델 재학습. Monitor model drift by using Amazon SageMaker Model Monitor.",
  "Retrieval Augmented Generation (RAG)": "검색 증강 생성 (RAG)",
  "Retrieval of relevant content": "관련 콘텐츠 검색",
  "Return on investment (ROI)": "투자 수익률 (ROI)",
  "Review the training data to check for biases. Include data from all demographics in the training data.": "편향을 확인하기 위해 학습 데이터 검토. 학습 데이터에 모든 인구 통계학적 데이터 포함",
  "Robotics": "로봇공학",
  "Root mean squared error (RMSE)": "평균 제곱근 오차 (RMSE)",
  "Run SageMaker training and Inference by using network Isolation.": "네트워크 격리를 사용하여 SageMaker 학습 및 추론 실행",
  "Run SageMaker training and inference by using SageMaker Experiments.": "SageMaker Experiments를 사용하여 SageMaker 학습 및 추론 실행",
  "Run a script in AWS Lambda that adds the examples to the training dataset.": "예제를 학습 데이터셋에 추가하는 AWS Lambda 스크립트 실행",
  "Run an application without provisioning or managing servers.": "서버를 프로비저닝하거나 관리하지 않고 애플리케이션 실행",
  "SageMaker Canvas": "Amazon SageMaker Canvas",
  "SageMaker Clarify": "SageMaker Clarify",
  "SageMaker Clarify 20": "SageMaker Clarify",
  "SageMaker Data Wrangler": "Amazon SageMaker Data Wrangler",
  "SageMaker Feature Store": "SageMaker Feature Store",
  "SageMaker Ground Truth": "SageMaker Ground Truth",
  "SageMaker Model Monitor": "SageMaker Model Monitor",
  "Sample data for training": "학습용 샘플 데이터",
  "Samples of only input messages": "입력 메시지만 샘플",
  "Samples of only output messages": "출력 메시지만 샘플",
  "Samples of pairs of input and output messages": "입력 및 출력 메시지 쌍 샘플",
  "Sampling bias": "샘플링 편향",
  "Scalable index management and nearest neighbor search capability": "확장 가능한 인덱스 관리 및 최근접 이웃 검색 기능",
  "Securing the company㑄s data in transit and at rest": "전송 중 및 저장 중인 회사 데이터 보안",
  "Segmenting customers based on type of investments": "투자 유형을 기반으로 고객 세분화",
  "Select a foundation model (FM) from Amazon Bedrock to build an application.": "애플리케이션을 구축하기 위해 Amazon Bedrock에서 파운데이션 모델(FM) 선택",
  "Select a large, diverse dataset to pre-train a new generative model.": "새 생성형 모델을 사전 학습하기 위해 대규모 다양한 데이터셋 선택",
  "Selecting the foundation model (FM) based on predefined criteria and metrics": "사전 정의된 기준과 메트릭을 기반으로 파운데이션 모델(FM) 선택",
  "Semantic robustness": "의미적 견고성",
  "Semi-supervised learning": "준지도 학습",
  "Sensitive information filters": "민감한 정보 필터",
  "Sentiment analysis of news articles": "뉴스 기사의 감정 분석",
  "Sentiment analysis scores from customer feedback after AI assistant interactions": "AI 어시스턴트 상호작용 후 고객 피드백의 감정 분석 점수",
  "Separate samples of input and output messages": "입력 및 출력 메시지의 별도 샘플",
  "Serverless inference": "서버리스 추론",
  "Serverless inference 3": "서버리스 추론 3",
  "Set a low limit on the number of tokens the FM can produce.": "FM이 생성할 수 있는 토큰 수에 낮은 제한 설정",
  "Set the access permissions for the S3 buckets to allow public access to enable access over the internet.": "S3 버킷의 액세스 권한을 공개 액세스 허용으로 설정",
  "Set the temperature to 1.": "온도를 1로 설정",
  "Set up Agents for Amazon Bedrock to supervise the model training.": "Set up Agents for Amazon Bedrock to supervise the model 학습.",
  "Set up experiments tracking.": "실험 추적 설정.",
  "Splitting text into manageable pieces of data 29": "텍스트를 관리 가능한 데이터 조각으로 분할",
  "Spot Instance": "Spot Instance",
  "Standardizing information about a model㐴s purpose, performance, and limitations.": "모델의 목적, 성능 및 한계에 대한 정보 표준화",
  "Static training 6": "Static 학습 6",
  "Store the model in Amazon S3 and host the model by using AWS Lambda.": "모델을 Amazon S3에 저장하고 AWS Lambda를 사용하여 모델 호스팅",
  "Summarization": "요약",
  "Summarize the response text depending on the age of the user so that younger users receive shorter responses.": "더 어린 사용자가 더 짧은 응답을 받도록 사용자 연령에 따라 응답 텍스트 요약",
  "Summarizing customer complaints": "고객 불만 요약",
  "Supervised fine-tuning": "지도 파인튜닝",
  "Supervised learning": "지도 학습",
  "Supervised learning with a continuously updated FAQ database": "지속적으로 업데이트되는 FAQ 데이터베이스를 사용한 지도 학습",
  "Supervised learning with a manually curated dataset of good responses and bad responses": "좋은 응답과 나쁜 응답의 수동으로 큐레이션된 데이터셋을 사용한 지도 학습",
  "Support for geospatial indexing and queries": "지리 공간 인덱싱 및 쿼리 지원",
  "Support vector machine": "지지 벡터 머신",
  "Syntax, semantic understanding, and code optimization capabilities": "구문, 의미 이해 및 코드 최적화 기능",
  "Tabular data": "테이블 형식 데이터",
  "Temperature": "온도",
  "Temperature value": "온도 값",
  "Text classification": "텍스트 분류",
  "Text completion": "Text completion",
  "Text completion model": "Text completion 모델",
  "Text data": "텍스트 데이터",
  "Text embedding model": "Text embedding 모델",
  "Text embeddings model": "Text embeddings 모델",
  "Text generation": "텍스트 생성",
  "Text summarization": "텍스트 요약",
  "Text-to-speech model": "Text-to-speech 모델",
  "The Top P value is too high.": "Top P 값이 너무 높습니다",
  "The company㐴s development framework is ISO certified.": "회사의 개발 프레임워크가 ISO 인증을 받았습니다",
  "The conversion rate of customers who purchase products after AI assistant interactions.": "AI 어시스턴트 상호작용 후 제품을 구매한 고객의 전환율",
  "The input tokens exceed the model㐴s context size.": "입력 토큰이 모델의 컨텍스트 크기를 초과합니다",
  "The method of collecting training data for AI systems": "AI 시스템을 위한 학습 데이터 수집 방법",
  "The model is biased.": "The model is biased.",
  "The model is overfit.": "모델이 과적합되었습니다",
  "The model is underfit.": "모델이 과소적합되었습니다",
  "The model requires prompt engineering.": "모델에 프롬프트 엔지니어링이 필요합니다",
  "The number of customer interactions with the AI assistant": "AI 어시스턴트와의 고객 상호작용 수",
  "The process of combining multiple AI models into one model": "The process of combining multiple AI models into one 모델",
  "The process of creating new AI algorithms": "새 AI 알고리즘 생성 프로세스",
  "The selected model does not support fine-tuning.": "선택한 모델은 파인튜닝을 지원하지 않습니다",
  "The temperature is set too high.": "온도가 너무 높게 설정되었습니다",
  "The use of a trained model to make predictions or decisions on unseen data": "보이지 않는 데이터에 대해 예측 또는 결정을 내리기 위해 학습된 모델 사용",
  "Threat detection": "위협 탐지",
  "Time series data": "시계열 데이터",
  "Time series data of general purpose historical sales": "일반 목적의 과거 판매 시계열 데이터",
  "Time series forecasting": "시계열 예측",
  "Time to first token": "첫 토큰까지의 시간",
  "Time used to train the model": "Time used to train the 모델",
  "To avoid database storage limitations for large text documents by storing parts or chunks of the text": "대용량 텍스트 문서의 데이터베이스 저장 제한을 피하기 위해 텍스트의 일부 또는 청크 저장",
  "To break text into smaller units for processing": "처리를 위해 텍스트를 더 작은 단위로 분할",
  "To compress text files": "텍스트 파일 압축",
  "To decrease the cost of storage by storing parts or chunks of the text": "텍스트의 일부 또는 청크를 저장하여 저장 비용 감소",
  "To encrypt text data": "To encrypt text 데이터",
  "To improve efficiency by avoiding the need to convert large text into vector embeddings": "대용량 텍스트를 벡터 임베딩으로 변환할 필요를 피하여 효율성 향상",
  "To improve the contextual relevancy of results retrieved from the vector index": "벡터 인덱스에서 검색된 결과의 컨텍스트 관련성 향상",
  "To translate text between languages": "언어 간 텍스트 번역",
  "Token length 5": "Token length 5",
  "Tokens": "Tokens",
  "Tokens are the basic units of input and output that a generative AI model operates on, representing words, subwords, or other linguistic units.": "토큰은 생성형 AI 모델이 작동하는 입력 및 출력의 기본 단위로, 단어, 하위 단어 또는 기타 언어 단위를 나타냅니다",
  "Tokens are the mathematical representations of words or concepts used in generative AI models.": "토큰은 생성형 AI 모델에서 사용되는 단어나 개념의 수학적 표현입니다",
  "Tokens are the pre-trained weights of a generative AI model that are fine-tuned for specific tasks.": "토큰은 특정 작업을 위해 파인튜닝된 생성형 AI 모델의 사전 훈련된 가중치입니다",
  "Tokens are the specific prompts or instructions given to a generative AI model to generate output.": "토큰은 출력을 생성하기 위해 생성형 AI 모델에 제공되는 특정 프롬프트 또는 지시사항입니다",
  "Tolerance": "Tolerance",
  "Top K": "Top K",
  "Topic modeling": "Topic modeling",
  "Total training time": "Total 학습 time",
  "Toxicity": "Toxicity",
  "Track the model changes by using Amazon Comprehend.": "Amazon Comprehend를 사용하여 모델 변경사항 추적",
  "Track the model changes by using Amazon Fraud Detector.": "Amazon Fraud Detector를 사용하여 모델 변경사항 추적",
  "Track the model changes by using Amazon SageMaker Model Cards.": "Amazon SageMaker Model Card",
  "Track the model changes by using Git.": "Git을 사용하여 모델 변경사항 추적",
  "Train a new FM.": "Train a new FM.",
  "Train models on Amazon SageMaker Autopilot.": "학습 models on Amazon SageMaker Autopilot.",
  "Train the model by using context data.": "컨텍스트 데이터를 사용하여 모델 학습",
  "Train the model for more epochs.": "에폭 감소",
  "Train the model on journals and textbooks.": "저널과 교과서로 모델 학습",
  "Training": "학습",
  "Training a model to recognize images of animals": "동물 이미지를 인식하도록 모델 학습",
  "Training on advanced ML algorithms": "고급 ML 알고리즘 학습",
  "Training on advanced coding skills 8": "고급 코딩 기술 학습",
  "Training on bias awareness and responsible AI": "편향 인식 및 책임 있는 AI 학습",
  "Training on data privacy and encryption protocols": "데이터 개인정보 보호 및 암호화 프로토콜 학습",
  "Training the agent to respond in the company㑄s language style": "회사의 언어 스타일로 응답하도록 에이전트 학습",
  "Training time": "학습 time",
  "Training time for each epoch": "학습 time for each epoch",
  "Transcribe call recordings by using Amazon Transcribe.": "Amazon Transcribe를 사용하여 통화 녹음 전사",
  "Transfer learning": "전이 학습",
  "Transformer 28": "Transformer 28",
  "Transformer-based language models can process only text data.": "트랜스포머 기반 언어 모델은 텍스트 데이터만 처리할 수 있습니다",
  "Transformer-based language models process data sequences one element at a time in cyclic iterations.": "트랜스포머 기반 언어 모델은 순환 반복에서 한 번에 하나의 요소씩 데이터 시퀀스를 처리합니다",
  "Transformer-based language models use convolutional layers to apply filters across an input to capture local patterns through filtered views.": "트랜스포머 기반 언어 모델은 필터링된 뷰를 통해 로컬 패턴을 캡처하기 위해 입력 전반에 필터를 적용하는 컨볼루션 레이어를 사용합니다",
  "Transformer-based language models use self-attention mechanisms to capture contextual relationships.": "트랜스포머 기반 언어 모델은 컨텍스트 관계를 캡처하기 위해 self-attention 메커니즘을 사용합니다",
  "Translation": "Translation",
  "Transparency": "투명성",
  "Tree of thoughts": "Tree of thoughts",
  "Turn on model invocation logging to collect messages.": "메시지를 수집하기 위해 모델 호출 로깅 활성화",
  "Underfitting": "과소적합",
  "Unique product IDs and corresponding user IDs": "Unique product IDs and corresponding 사용r IDs",
  "Unsupervised learning": "비지도 학습",
  "Unsupervised learning to find clusters of similar customer inquiries": "유사한 고객 문의의 클러스터를 찾기 위한 비지도 학습",
  "Upload PDF documents to an Amazon Bedrock knowledge base. Use the knowledge base to provide context when users submit prompts to Amazon Bedrock.": "PDF 문서를 Amazon Bedrock 지식 베이스에 업로드. 사용자가 Amazon Bedrock에 프롬프트를 제출할 때 지식 베이스를 사용하여 컨텍스트 제공",
  "Use AWS AI Service Cards for transparency and understanding models.": "투명성 및 모델 이해를 위해 AWS AI Service Cards 사용",
  "Use AWS Audit Manager to prepare IT audit and compliance reports.": "AWS Audit Manager를 사용하여 IT 감사 및 규정 준수 보고서 작성",
  "Use AWS Batch to host the model and serve predictions.": "모델을 호스팅하고 예측을 제공하기 위해 AWS Batch 사용",
  "Use AWS Config to query compliance metadata by using natural language.": "자연어를 사용하여 규정 준수 메타데이터를 쿼리하기 위해 AWS Config 사용",
  "Use AWS Glue Data Quality to make corrections to each image.": "각 이미지에 대한 수정을 수행하기 위해 AWS Glue Data Quality 사용",
  "Use AWS Glue to set up data encryption across the company㐴s data catalog.": "회사의 데이터 카탈로그 전반에 데이터 암호화를 설정하기 위해 AWS Glue 사용",
  "Use AWS Identity and Access Management (IAM) policies to restrict model access.": "모델 액세스를 제한하기 위해 AWS Identity and Access Management (IAM) 정책 사용",
  "Use AWS Identity and Access Management (IAM) service roles to restrict model subscription.": "모델 구독을 제한하기 위해 AWS Identity and Access Management (IAM) 서비스 역할 사용",
  "Use AWS Key Management Service (AWS KMS) keys to encrypt the data.": "데이터를 암호화하기 위해 AWS Key Management Service (AWS KMS) 키 사용",
  "Use AWS Lake Formation to manage centralized data governance and cross-account data sharing.": "중앙 집중식 데이터 거버넌스 및 계정 간 데이터 공유를 관리하기 위해 AWS Lake Formation 사용",
  "Use AWS PrivateLink and a VPC.": "AWS PrivateLink 및 VPC 사용",
  "Use AWS PrivateLink to configure a private connection between the company㐴s VPC and Amazon Bedrock.": "AWS PrivateLink를 사용하여 회사의 VPC와 Amazon Bedrock 간의 프라이빗 연결 구성",
  "Use AWS PrivateLink to connect the VPC and Amazon Bedrock.": "VPC와 Amazon Bedrock을 연결하기 위해 AWS PrivateLink 사용",
  "Use AWS Security Token Service (AWS STS) to generate temporary credentials for model use.": "모델 사용을 위한 임시 자격 증명을 생성하기 위해 AWS Security Token Service (AWS STS) 사용",
  "Use AWS Trusted Advisor checks to eliminate bias.": "편향을 제거하기 위해 AWS Trusted Advisor 체크 사용",
  "Use Agents for Amazon Bedrock with Amazon Bedrock knowledge bases to build the application.": "Amazon Bedrock Knowledge Base 사용",
  "Use Agents for Amazon Bedrock with Amazon Fraud Detector to build the application.": "Amazon Fraud Detector와 함께 Agents for Amazon Bedrock을 사용하여 애플리케이션 구축",
  "Use Amazon API Gateway to host the model and serve predictions.": "모델을 호스팅하고 예측을 제공하기 위해 Amazon API Gateway 사용",
  "Use Amazon Bedrock Agents.": "Amazon Bedrock Agents 사용",
  "Use Amazon Bedrock Guardrails content filters and denied topics.": "Amazon Bedrock Guardrails 콘텐츠 필터 및 거부된 주제 사용",
  "Use Amazon Bedrock Knowledge Bases.": "Amazon Bedrock Knowledge Bases 사용",
  "Use Amazon Bedrock Stable Diffusion 3.5 Large to generate images based on text inputs.": "텍스트 입력을 기반으로 이미지를 생성하기 위해 Amazon Bedrock Stable Diffusion 3.5 Large 사용",
  "Use Amazon Bedrock with On-Demand Throughput.": "온디맨드 처리량으로 Amazon Bedrock 사용",
  "Use Amazon Bedrock with Provisioned Throughput.": "프로비저닝된 처리량으로 Amazon Bedrock 사용",
  "Use Amazon CloudFront to deploy the model.": "Amazon CloudFront를 사용하여 모델 배포",
  "Use Amazon CloudFront to restrict access to the company㐴s private content.": "회사의 프라이빗 콘텐츠에 대한 액세스를 제한하기 위해 Amazon CloudFront 사용",
  "Use Amazon CloudWatch Logs to make models explainable and to monitor for bias.": "Amazon CloudWatch Logs를 사용하여 모델을 설명 가능하게 만들고 편향성 모니터링",
  "Use Amazon CloudWatch logs and metrics.": "Amazon CloudWatch 로그 및 메트릭 사용",
  "Use Amazon CloudWatch to analyze customer orders.": "고객 주문을 분석하기 위해 Amazon CloudWatch 사용",
  "Use Amazon Comprehend Medical to extract relevant medical entities and relationships. Apply rule-based logic to structure and format summaries.": "관련 의료 개체 및 관계를 추출하기 위해 Amazon Comprehend Medical 사용. 규칙 기반 로직을 적용하여 요약 구조화 및 형식 지정",
  "Use Amazon Comprehend toxicity detection.": "Amazon Comprehend 독성 감지 사용",
  "Use Amazon Fraud Detector to detect potentially fraudulent online activities.": "잠재적으로 사기성 온라인 활동을 감지하기 위해 Amazon Fraud Detector 사용",
  "Use Amazon Inspector to monitor SageMaker Studio.": "SageMaker Studio를 모니터링하기 위해 Amazon Inspector 사용",
  "Use Amazon Inspector to monitor model access.": "모델 액세스를 모니터링하기 위해 Amazon Inspector 사용",
  "Use Amazon Macie to monitor SageMaker Studio.": "SageMaker Studio를 모니터링하기 위해 Amazon Macie 사용",
  "Use Amazon Macie to scan the model㑄s output for sensitive data and set up alerts for potential violations.": "Amazon Macie",
  "Use Amazon Personalize and iterate with historical data.": "Amazon Personalize를 사용하고 과거 데이터로 반복",
  "Use Amazon Personalize to analyze patient engagement patterns. Integrate the output with a general purpose text summarization tool.": "환자 참여 패턴을 분석하기 위해 Amazon Personalize 사용. 출력을 범용 텍스트 요약 도구와 통합",
  "Use Amazon Personalize to generate responses.": "응답을 생성하기 위해 Amazon Personalize 사용",
  "Use Amazon Personalize to save conversation history.": "대화 기록을 저장하기 위해 Amazon Personalize 사용",
  "Use Amazon Personalize with Amazon Bedrock knowledge bases to build the application.": "Amazon Bedrock Knowledge Base 사용",
  "Use Amazon Polly to create an audiobook based on story texts.": "Amazon Polly를 사용하여 스토리 텍스트를 기반으로 오디오북 생성",
  "Use Amazon Polly to generate voice-overs in other languages.": "다른 언어로 음성 오버를 생성하기 위해 Amazon Polly 사용",
  "Use Amazon Polly to monitor comments.": "댓글을 모니터링하기 위해 Amazon Polly 사용",
  "Use Amazon Q Business to build a custom Q App. 2": "Amazon Q Business",
  "Use Amazon Rekognition moderation.": "Amazon Rekognition 조정 사용",
  "Use Amazon Rekognition to analyze image contents and detect text attributes.": "이미지 콘텐츠를 분석하고 텍스트 속성을 감지하기 위해 Amazon Rekognition 사용",
  "Use Amazon Rekognition to optimize the model.": "Amazon Rekognition을 사용하여 모델 최적화",
  "Use Amazon SageMaker Ground Truth to label the examples.": "예제에 라벨을 지정하기 위해 Amazon SageMaker Ground Truth 사용",
  "Use Amazon SageMaker JumpStart.": "Amazon SageMaker JumpStart 사용",
  "Use Amazon SageMaker Serverless Inference to deploy the model.": "Amazon SageMaker 서버리스 추론을 사용하여 모델 배포",
  "Use Amazon SageMaker and iterate with newer data.": "Amazon SageMaker를 사용하고 최신 데이터로 반복",
  "Use Amazon SageMaker built-in algorithms to train the model.": "Amazon SageMaker 내장 알고리즘을 사용하여 모델 학습",
  "Use Amazon SageMaker endpoints to deploy a large language model (LLM) to redact sensitive data.": "Amazon SageMaker 엔드포인트",
  "Use Amazon SageMaker to build the application by training a new ML model.": "새 ML 모델을 학습하여 애플리케이션을 구축하기 위해 Amazon SageMaker 사용",
  "Use Amazon Textract and Amazon Translate to generate subtitles in other languages.": "다른 언어로 자막을 생성하기 위해 Amazon Textract 및 Amazon Translate 사용",
  "Use Amazon Textract to convert scanned documents into digital text. Design a keyword extraction system to generate summaries.": "스캔한 문서를 디지털 텍스트로 변환하기 위해 Amazon Textract 사용. 요약을 생성하기 위한 키워드 추출 시스템 설계",
  "Use Amazon Textract to generate voice-overs in other languages.": "다른 언어로 음성 오버를 생성하기 위해 Amazon Textract 사용",
  "Use Amazon Transcribe and Amazon Translate to generate subtitles in other languages.": "다른 언어로 자막을 생성하기 위해 Amazon Transcribe 및 Amazon Translate 사용",
  "Use Amazon Translate to generate voice-overs in other languages.": "다른 언어로 음성 오버를 생성하기 위해 Amazon Translate 사용",
  "Use GPU-powered Amazon EC2 instances.": "GPU 기반 Amazon EC2 인스턴스 사용",
  "Use Guardrails for Amazon Bedrock to filter content. Set up Amazon CloudWatch alarms for notification of policy violations.": "콘텐츠를 필터링하기 위해 Amazon Bedrock용 Guardrails 사용. 정책 위반 알림을 위한 Amazon CloudWatch 알람 설정",
  "Use Provisioned Throughput for the LLM.": "LLM을 위한 프로비저닝된 처리량 사용",
  "Use Provisioned Throughput.": "프로비저닝된 처리량 사용",
  "Use Retrieval Augmented Generation (RAG) with prompt engineering techniques.": "프롬프트 엔지니어링 기법과 함께 검색 증강 생성(RAG) 사용",
  "Use Retrieval Augmented Generation (RAG) with the fine-tuned model.": "파인튜닝된 모델과 함께 검색 증강 생성(RAG) 사용",
  "Use Retrieval Augmented Generation (RAG).": "검색 증강 생성(RAG) 사용",
  "Use a binary classification model to generate code reviews.": "이진 분류 모델을 사용하여 코드 리뷰 생성",
  "Use a deep learning model with many hidden layers.": "딥러닝 모델",
  "Use a deep learning neural network to perform speech recognition.": "음성 인식을 수행하기 위해 딥러닝 신경망 사용",
  "Use a different FM.": "Use a different FM.",
  "Use a foundation model (FM) that is trained to not hallucinate.": "환각하지 않도록 학습된 파운데이션 모델(FM) 사용",
  "Use a generative adversarial network (GAN) model to classify the images.": "생성적 적대 신경망(GAN)",
  "Use a higher temperature value.": "더 높은 온도 값 사용",
  "Use a large language model (LLM) to perform natural language processing (NLP) for sentiment analysis.": "자연어 처리 (NLP)",
  "Use a more detailed prompt.": "더 자세한 프롬프트 사용",
  "Use a natural language processing (NLP) tool to generate code.": "자연어 처리 (NLP)",
  "Use a negative prompt.": "부정 프롬프트 사용",
  "Use a pre-trained deep learning model. Fine-tune the model on the dataset.": "딥러닝 모델",
  "Use a recommendation engine algorithm to detect user sentiment.": "추천 엔진 알고리즘을 사용하여 사용자 감정 탐지",
  "Use a regression algorithm to classify the feedback based on predefined categories. Then, analyze user sentiment.": "회귀 알고리즘을 사용하여 미리 정의된 범주를 기반으로 피드백 분류. 그런 다음 사용자 감정 분석",
  "Use a rule-based system instead of an ML model.": "ML 모델 대신 규칙 기반 시스템 사용",
  "Use a support vector machine (SVM) with manually engineered features for classification.": "분류를 위해 수동으로 설계된 특성이 있는 지지 벡터 머신(SVM) 사용",
  "Use a time series algorithm to predict user sentiment based on past feedback.": "시계열 알고리즘을 사용하여 과거 피드백을 기반으로 사용자 감정 예측",
  "Use a trained model to predict patient readmission.": "학습된 모델을 사용하여 환자 재입원 예측",
  "Use all the PDF documents to fine-tune a model with Amazon Bedrock. Use the fine-tuned model to process user prompts.": "모든 PDF 문서를 사용하여 Amazon Bedrock으로 모델 파인튜닝. 파인튜닝된 모델을 사용하여 사용자 프롬프트 처리",
  "Use ambiguous prompts.": "모호한 프롬프트 사용",
  "Use an Amazon Bedrock large language model (LLM) with a high temperature.": "높은 온도를 가진 Amazon Bedrock 대형 언어 모델(LLM) 사용",
  "Use another foundation model (FM).": "다른 파운데이션 모델(FM) 사용",
  "Use appropriate metrics and assess model performance.": "적절한 메트릭을 사용하고 모델 성능 평가",
  "Use automatic evaluation on Amazon Personalize.": "Amazon Personalize에서 자동 평가 사용",
  "Use batch inferencing to process detailed responses.": "상세한 응답을 처리하기 위해 배치 추론 사용",
  "Use chain-of-thought prompting to produce secure responses.": "Use Chain-of-thought 프롬프팅 (사고 과정 프롬프팅) to produce secure responses.",
  "Use chain-of-thought prompting with hidden reasoning steps to ignore explicit domain instructions.": "명시적 도메인 지시사항을 무시하기 위해 숨겨진 추론 단계가 있는 chain-of-thought 프롬프팅 사용",
  "Use chain-of-thought reasoning to deduce the correct style and complexity for a response suitable for that user.": "해당 사용자에게 적합한 응답에 대한 올바른 스타일과 복잡성을 추론하기 위해 chain-of-thought 추론 사용",
  "Use code that will calculate probability by using simple rules and computations.": "간단한 규칙과 계산을 사용하여 확률을 계산하는 코드 사용",
  "Use content moderation on Amazon Rekognition.": "Amazon Rekognition에서 콘텐츠 조정 사용",
  "Use data from only customers who match the demographics of the company㑄s overall customer base.": "회사의 전체 고객 기반의 인구 통계와 일치하는 고객의 데이터만 사용",
  "Use data pre-processing and remove any data that causes hallucinations.": "데이터 전처리를 사용하고 환각을 유발하는 데이터 제거",
  "Use data to identify patient patterns and correlations.": "환자 패턴 및 상관관계를 식별하기 위해 데이터 사용",
  "Use domain adaptation fine-tuning to adapt the FM to complex scientific terms.": "복잡한 과학 용어에 FM을 적응시키기 위해 도메인 적응 파인튜닝 사용",
  "Use few-shot prompting to add domain-specific context and explicit instructions.": "도메인별 컨텍스트 및 명시적 지시사항을 추가하기 위해 few-shot 프롬프팅 사용",
  "Use few-shot prompting to define how the FM can answer the questions.": "FM이 질문에 답할 수 있는 방법을 정의하기 위해 few-shot 프롬프팅 사용",
  "Use few-shot prompting.": "Few-shot 프롬프팅 사용",
  "Use generative AI summarization to generate human-like text.": "인간과 같은 텍스트를 생성하기 위해 생성형 AI 요약 사용",
  "Use model evaluation on Amazon Bedrock.": "Amazon Bedrock에서 모델 평가 사용",
  "Use negative prompts.": "부정 프롬프트 사용",
  "Use positive prompts.": "긍정 프롬프트 사용",
  "Use pre-training and data augmentation on the company policy data.": "Use pre-학습 and data augmentation on the company policy data.",
  "Use prompt engineering techniques to tell the model to look for information in Amazon S3.": "프롬프트 엔지니어링 기법을 사용하여 모델에 정보를 찾도록 지시",
  "Use prompt engineering to add all the PDF files as context to the user prompt when the prompt is submitted to Amazon Bedrock.": "프롬프트가 Amazon Bedrock에 제출될 때 모든 PDF 파일을 사용자 프롬프트의 컨텍스트로 추가하기 위해 프롬프트 엔지니어링 사용",
  "Use prompt engineering to add one PDF file as context to the user prompt when the prompt is submitted to Amazon Bedrock.": "프롬프트가 Amazon Bedrock에 제출될 때 하나의 PDF 파일을 사용자 프롬프트의 컨텍스트로 추가하기 위해 프롬프트 엔지니어링 사용",
  "Use prompt engineering. 13": "프롬프트 엔지니어링 사용",
  "Use public model leaderboards to identify the model.": "모델을 식별하기 위해 공개 모델 리더보드 사용",
  "Use reinforcement learning to train a model to return the probability.": "강화 학습을 사용하여 확률을 반환하는 모델 학습",
  "Use sentiment analysis on Amazon Comprehend.": "Amazon Comprehend에서 감정 분석 사용",
  "Use supervised learning to create a regression model that will predict probability.": "지도 학습을 사용하여 확률을 예측하는 회귀 모델 생성",
  "Use the Amazon Bedrock API.": "Amazon Bedrock API 사용",
  "Use the Amazon Nova Canvas model on Amazon Bedrock to generate intermediate images. Use video editing software to create videos.": "중간 이미지를 생성하기 위해 Amazon Bedrock의 Amazon Nova Canvas 모델 사용. 비디오를 생성하기 위해 비디오 편집 소프트웨어 사용",
  "Use the Amazon Nova Pro model on Amazon Bedrock to generate videos.": "Amazon Bedrock의 Amazon Nova Pro 모델을 사용하여 비디오 생성",
  "Use the Amazon Nova Reel model on Amazon Bedrock to generate videos.": "Amazon Bedrock의 Amazon Nova Reel 모델을 사용하여 비디오 생성",
  "Use the Amazon Textract real-time document processing feature.": "Amazon Textract 실시간 문서 처리 기능 사용",
  "Use the Amazon Titan Image Generator model on Amazon Bedrock to generate intermediate images. Use video editing software to create videos.": "중간 이미지를 생성하기 위해 Amazon Bedrock의 Amazon Titan Image Generator 모델 사용. 비디오를 생성하기 위해 비디오 편집 소프트웨어 사용",
  "Use the Amazon Translate real-time translation feature.": "Amazon Translate 실시간 번역 기능 사용",
  "Use the BERTScore to estimate the absolute translation quality of the two methods.": "BERTScore를 사용하여 두 방법의 절대 번역 품질 추정",
  "Use the BERTScore to estimate the relative translation quality of the two methods.": "BERTScore를 사용하여 두 방법의 상대 번역 품질 추정",
  "Use the Bilingual Evaluation Understudy (BLEU) score to estimate the absolute translation quality of the two methods.": "양국어 평가 보조 (BLEU) 점수",
  "Use the Bilingual Evaluation Understudy (BLEU) score to estimate the relative translation quality of the two methods.": "양국어 평가 보조 (BLEU) 점수",
  "Use the MASK㏇IMAGE㏇BLACK mask source option.": "MASK㏇IMAGE㏇BLACK 마스크 소스 옵션 사용",
  "Use the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) technique to ensure that the model is 100㚠 accurate.": "모델이 100% 정확하도록 보장하기 위해 요약 평가를 위한 재현율 지향 보조(ROUGE) 기법 사용",
  "Use the model InvocationLatency runtime metrics in Amazon CloudWatch when trying models.": "모델을 시도할 때 Amazon CloudWatch의 모델 InvocationLatency 런타임 메트릭 사용",
  "Use the model with on-demand throughput on Amazon Bedrock.": "Amazon Bedrock의 온디맨드 처리량으로 모델 사용",
  "Use traditional ML algorithms with custom features extracted from the dataset.": "데이터셋에서 추출한 사용자 정의 특성이 있는 전통적인 ML 알고리즘 사용",
  "Use transfer learning.": "전이 학습 사용.",
  "Use unsupervised learning to create a model that will estimate probability density.": "비지도 학습을 사용하여 확률 밀도를 추정하는 모델 생성",
  "Use unsupervised learning.": "비지도 학습 사용.",
  "Use zero-shot prompting to augment retrieval from a product database.": "제품 데이터베이스에서 검색을 향상시키기 위해 zero-shot 프롬프팅 사용",
  "Use zero-shot prompts.": "Zero-shot 프롬프트 사용",
  "User inputs and model outputs are anonymized and shared with third-party model providers.": "사용자 입력 및 모델 출력이 익명화되어 서드파티 모델 제공자와 공유됩니다",
  "User inputs and model outputs are not shared with any third-party model providers.": "사용자 입력 및 모델 출력이 서드파티 모델 제공자와 공유되지 않습니다",
  "User inputs and model outputs are redacted before the inputs and outputs are shared with third-party model providers.": "입력 및 출력이 서드파티 모델 제공자와 공유되기 전에 사용자 입력 및 모델 출력이 편집됩니다",
  "User inputs are kept confidential, but model outputs are shared with third-party model providers.": "사용자 입력은 기밀로 유지되지만 모델 출력은 서드파티 모델 제공자와 공유됩니다",
  "User-generated content": "사용자 생성 콘텐츠",
  "Using a third-party enterprise application that has embedded generative AI features.": "내장된 생성형 AI 기능이 있는 서드파티 엔터프라이즈 애플리케이션 사용",
  "Using an ML model to forecast product demand": "제품 수요를 예측하기 위해 ML 모델 사용",
  "Using an analytics dashboard to track website traffic and user behavior": "웹사이트 트래픽 및 사용자 행동을 추적하기 위해 분석 대시보드 사용",
  "Value of the loss function": "손실 함수 값",
  "Violence": "Violence",
  "Watermark detection for images": "이미지 워터마크 탐지",
  "WaveNet": "WaveNet",
  "Website engagement rate": "웹사이트 참여율",
  "Word error rate": "단어 오류율",
  "Word filters": "Word filters",
  "Writing the confidence level in the response": "응답에 신뢰도 수준 작성",
  "XGBoost": "XGBoost",
  "Zero-shot prompting": "Zero-shot 프롬프팅 (샘플 없음 프롬프팅)"
}